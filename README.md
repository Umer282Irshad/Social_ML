# Social_ML
Introducing a groundbreaking client-server application that combines the power of Data Parallelism and ensemble networks for training machine learning models. Developed by me, Umer, this innovative system revolutionizes the training process by harnessing the collective intelligence of multiple machines. By leveraging the technique of Data Parallelism, the application efficiently distributes model training, while the ensemble networks enhance model performance and robustness. Experience the seamless collaboration and enhanced accuracy achieved through the synergy of Data Parallelism and ensemble networks in this cutting-edge client-server app. Unleash the true potential of distributed machine learning training like never before.

Following Libraries are used in this project:
  1. Tensorflow
  2. Keras
  3. ML_Socket
  4. Socket

By dividing the data of any machine learning model into chunks, this system enables parallel training on multiple machines connected over the internet. Each machine independently trains a separate model on its assigned data chunk, harnessing the power of distributed computing. Upon completion, the trained models are seamlessly transmitted to the main machine that initiated the training. At the main machine, the models are intelligently combined using ensemble networks, resulting in significantly enhanced accuracy and predictive performance. Experience the game-changing capabilities of distributed training and ensemble networks with this cutting-edge client-server application, optimizing the training process like never before.
